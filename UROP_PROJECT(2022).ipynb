{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UROP Project\n",
    "## Plant Disease Detection Using Image Processing\n",
    "#### Group:\n",
    "####    N.Akhila(AP19110010322)\n",
    "####    K.Manasa(AP19110010343)\n",
    "####    S.Navya(AP19110010417)\n",
    "####    K.N.P.Suparnika(AP19110010480)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "os.chdir(r\"C:\\Users\\pavan\\Downloads\\Plant_leave_diseases_dataset_without_augmentation\")\n",
    "all_subdirs = [d for d in os.listdir('.') if os.path.isdir(d)]\n",
    "#all_subdirs contain the names of leaf category\n",
    "# folder has the paths to reach the folder. These two will help to extract the images from the folders.\n",
    "folders=[]\n",
    "for dirs in all_subdirs:\n",
    "    dir = os.path.join(r\"C:\\Users\\pavan\\Downloads\\Plant_leave_diseases_dataset_without_augmentation\", dirs)\n",
    "    os.chdir(dir)\n",
    "    current = os.getcwd()\n",
    "    new = str(current).split(\"/\")\n",
    "    folders.append(new)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(all_subdirs)\n",
    "#print(folders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_images=[] #all_images conatins the images in each of the folder\n",
    "def readimg(s):\n",
    "    images = [cv2.imread(file) for file in glob.glob(s+\"\\*.jpg\")]\n",
    "    all_images.append(images)   \n",
    "for i in folders:\n",
    "    readimg(i[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pre-processing of Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the required packages\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from skimage.feature import greycomatrix, greycoprops\n",
    "from skimage import io, color, img_as_ubyte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "z=-1\n",
    "a=[]\n",
    "for i in all_images:\n",
    "    z+=1\n",
    "    p=[]\n",
    "    for img in i:\n",
    "        k=[]\n",
    "        grayscale = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) #converts the image into grayscale mode\n",
    "        #guassian filter is anlow pass filter used for reducing noise(high frequency components) and blurring regions of an image\n",
    "        grayscale=cv2.GaussianBlur(grayscale,(7,7),0)\n",
    "        histr = cv2.calcHist([grayscale],[0],None,[256],[0,256])\n",
    "        otsu_threshold, image_result=cv2.threshold(grayscale,0,255,cv2.THRESH_OTSU+cv2.THRESH_BINARY )\n",
    "        image_result[image_result==255],image_result[image_result==0]=1,255\n",
    "        image_result[image_result==1]=0\n",
    "        kernel = np.ones((5,5),np.uint8)\n",
    "        dilation = cv2.dilate(image_result,kernel,iterations = 1)\n",
    "        erosion = cv2.erode(image_result,kernel,iterations = 1)\n",
    "        closing = cv2.morphologyEx(image_result, cv2.MORPH_CLOSE, kernel)\n",
    "        contours,hierarchy = cv2.findContours(dilation, 1, 2)\n",
    "        cnt = contours[0]\n",
    "        area = cv2.contourArea(cnt)\n",
    "        perimeter = cv2.arcLength(cnt,True)\n",
    "        k.append(area)\n",
    "        k.append(perimeter)\n",
    "        b,g,r = cv2.split(img) \n",
    "        k.append(np.mean(r))\n",
    "        k.append(np.mean(b))\n",
    "        k.append(np.mean(g))\n",
    "        k.append(np.std(r))\n",
    "        k.append(np.std(b))\n",
    "        k.append(np.std(g))\n",
    "        bitand=[]\n",
    "        bitand.append(cv2.bitwise_and(closing,r))\n",
    "        bitand.append(cv2.bitwise_and(closing,g))\n",
    "        bitand.append(cv2.bitwise_and(closing,b))\n",
    "        image= cv2.merge([r,g,b])\n",
    "        gray = color.rgb2gray(image)\n",
    "        image = img_as_ubyte(gray)\n",
    "        bins = np.array([0, 16, 32, 48, 64, 80, 96, 112, 128, 144, 160, 176, 192, 208, 224, 240, 255]) #16-bit\n",
    "        inds = np.digitize(image, bins)\n",
    "        max_value = inds.max()+1\n",
    "        matrix_coocurrence = greycomatrix(inds, [1], [0, np.pi/4, np.pi/2, 3*np.pi/4], levels=max_value, normed=False, symmetric=False)\n",
    "        k+=greycoprops(matrix_coocurrence, 'contrast').tolist()[0]\n",
    "        k+= greycoprops(matrix_coocurrence, 'dissimilarity').tolist()[0]\n",
    "        k+= greycoprops(matrix_coocurrence, 'homogeneity').tolist()[0]\n",
    "        k+= greycoprops(matrix_coocurrence, 'energy').tolist()[0]\n",
    "        k+= greycoprops(matrix_coocurrence, 'correlation').tolist()[0]\n",
    "        k+= greycoprops(matrix_coocurrence, 'ASM').tolist()[0]\n",
    "        k.append(all_subdirs[z])\n",
    "        p.append(k)\n",
    "    a.append(p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "h=[\"area\",\"perimeter\",\"r_mean\",\"b_mean\",\"g_mean\",\"r_std\",\"b_std\",\"g_std\",\"contrast_1\",\"contrast_2\",\"contrast_3\",\"contrast_4\",\"dissimlarity_1\",\"dissimlarity_2\",\"dissimlarity_3\",\"dissimlarity_4\",\"homogeneity_1\",\"homogeneity_2\",\"homogeneity_3\",\"homogeneity_4\",\"energy_1\",\"energy_2\",\"energy_3\",\"energy_4\",\"correlation_1\",\"correlation_2\",\"correlation_3\",\"correlation_4\",\"asm_1\",\"asm_2\",\"asm_3\",\"asm_4\",\"class_level\"]\n",
    "with open(r'C:\\Users\\pavan\\Downloads\\leaf_data_set.csv', 'w', encoding='UTF8', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "\n",
    "    # write the header\n",
    "    writer.writerow(h)\n",
    "\n",
    "    # write multiple rows\n",
    "    for i in range(len(a)):\n",
    "        writer.writerows(a[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>area</th>\n",
       "      <th>perimeter</th>\n",
       "      <th>r_mean</th>\n",
       "      <th>b_mean</th>\n",
       "      <th>g_mean</th>\n",
       "      <th>r_std</th>\n",
       "      <th>b_std</th>\n",
       "      <th>g_std</th>\n",
       "      <th>contrast_1</th>\n",
       "      <th>contrast_2</th>\n",
       "      <th>...</th>\n",
       "      <th>energy_4</th>\n",
       "      <th>correlation_1</th>\n",
       "      <th>correlation_2</th>\n",
       "      <th>correlation_3</th>\n",
       "      <th>correlation_4</th>\n",
       "      <th>asm_1</th>\n",
       "      <th>asm_2</th>\n",
       "      <th>asm_3</th>\n",
       "      <th>asm_4</th>\n",
       "      <th>class_level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>7.656854</td>\n",
       "      <td>113.009567</td>\n",
       "      <td>98.667679</td>\n",
       "      <td>124.975052</td>\n",
       "      <td>52.151884</td>\n",
       "      <td>62.930396</td>\n",
       "      <td>45.098714</td>\n",
       "      <td>4.404412</td>\n",
       "      <td>4.832449</td>\n",
       "      <td>...</td>\n",
       "      <td>0.132954</td>\n",
       "      <td>0.741145</td>\n",
       "      <td>0.715799</td>\n",
       "      <td>0.733520</td>\n",
       "      <td>0.725497</td>\n",
       "      <td>0.018605</td>\n",
       "      <td>0.017531</td>\n",
       "      <td>0.018137</td>\n",
       "      <td>0.017677</td>\n",
       "      <td>Apple___Apple_scab</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>5.656854</td>\n",
       "      <td>119.944580</td>\n",
       "      <td>110.333755</td>\n",
       "      <td>128.267365</td>\n",
       "      <td>54.634916</td>\n",
       "      <td>63.561602</td>\n",
       "      <td>45.730131</td>\n",
       "      <td>4.884544</td>\n",
       "      <td>5.526997</td>\n",
       "      <td>...</td>\n",
       "      <td>0.136741</td>\n",
       "      <td>0.731875</td>\n",
       "      <td>0.696846</td>\n",
       "      <td>0.716856</td>\n",
       "      <td>0.718881</td>\n",
       "      <td>0.019944</td>\n",
       "      <td>0.018362</td>\n",
       "      <td>0.019128</td>\n",
       "      <td>0.018698</td>\n",
       "      <td>Apple___Apple_scab</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67.5</td>\n",
       "      <td>44.526911</td>\n",
       "      <td>128.512802</td>\n",
       "      <td>123.811050</td>\n",
       "      <td>128.722946</td>\n",
       "      <td>44.779738</td>\n",
       "      <td>59.958839</td>\n",
       "      <td>40.243447</td>\n",
       "      <td>4.249173</td>\n",
       "      <td>4.387190</td>\n",
       "      <td>...</td>\n",
       "      <td>0.145336</td>\n",
       "      <td>0.691007</td>\n",
       "      <td>0.681434</td>\n",
       "      <td>0.685975</td>\n",
       "      <td>0.689367</td>\n",
       "      <td>0.021931</td>\n",
       "      <td>0.021225</td>\n",
       "      <td>0.021812</td>\n",
       "      <td>0.021123</td>\n",
       "      <td>Apple___Apple_scab</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>315.0</td>\n",
       "      <td>92.142135</td>\n",
       "      <td>104.932266</td>\n",
       "      <td>105.313095</td>\n",
       "      <td>113.368484</td>\n",
       "      <td>57.670711</td>\n",
       "      <td>66.643183</td>\n",
       "      <td>50.720956</td>\n",
       "      <td>4.353784</td>\n",
       "      <td>4.785006</td>\n",
       "      <td>...</td>\n",
       "      <td>0.122645</td>\n",
       "      <td>0.798387</td>\n",
       "      <td>0.778590</td>\n",
       "      <td>0.787288</td>\n",
       "      <td>0.779954</td>\n",
       "      <td>0.015750</td>\n",
       "      <td>0.014900</td>\n",
       "      <td>0.015421</td>\n",
       "      <td>0.015042</td>\n",
       "      <td>Apple___Apple_scab</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>5.656854</td>\n",
       "      <td>121.570267</td>\n",
       "      <td>111.120163</td>\n",
       "      <td>125.261810</td>\n",
       "      <td>38.714286</td>\n",
       "      <td>48.490118</td>\n",
       "      <td>31.778066</td>\n",
       "      <td>3.799203</td>\n",
       "      <td>4.137978</td>\n",
       "      <td>...</td>\n",
       "      <td>0.182029</td>\n",
       "      <td>0.571445</td>\n",
       "      <td>0.533520</td>\n",
       "      <td>0.533314</td>\n",
       "      <td>0.533836</td>\n",
       "      <td>0.035068</td>\n",
       "      <td>0.033023</td>\n",
       "      <td>0.034162</td>\n",
       "      <td>0.033135</td>\n",
       "      <td>Apple___Apple_scab</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    area  perimeter      r_mean      b_mean      g_mean      r_std      b_std  \\\n",
       "0    4.0   7.656854  113.009567   98.667679  124.975052  52.151884  62.930396   \n",
       "1    2.0   5.656854  119.944580  110.333755  128.267365  54.634916  63.561602   \n",
       "2   67.5  44.526911  128.512802  123.811050  128.722946  44.779738  59.958839   \n",
       "3  315.0  92.142135  104.932266  105.313095  113.368484  57.670711  66.643183   \n",
       "4    2.0   5.656854  121.570267  111.120163  125.261810  38.714286  48.490118   \n",
       "\n",
       "       g_std  contrast_1  contrast_2  ...  energy_4  correlation_1  \\\n",
       "0  45.098714    4.404412    4.832449  ...  0.132954       0.741145   \n",
       "1  45.730131    4.884544    5.526997  ...  0.136741       0.731875   \n",
       "2  40.243447    4.249173    4.387190  ...  0.145336       0.691007   \n",
       "3  50.720956    4.353784    4.785006  ...  0.122645       0.798387   \n",
       "4  31.778066    3.799203    4.137978  ...  0.182029       0.571445   \n",
       "\n",
       "   correlation_2  correlation_3  correlation_4     asm_1     asm_2     asm_3  \\\n",
       "0       0.715799       0.733520       0.725497  0.018605  0.017531  0.018137   \n",
       "1       0.696846       0.716856       0.718881  0.019944  0.018362  0.019128   \n",
       "2       0.681434       0.685975       0.689367  0.021931  0.021225  0.021812   \n",
       "3       0.778590       0.787288       0.779954  0.015750  0.014900  0.015421   \n",
       "4       0.533520       0.533314       0.533836  0.035068  0.033023  0.034162   \n",
       "\n",
       "      asm_4         class_level  \n",
       "0  0.017677  Apple___Apple_scab  \n",
       "1  0.018698  Apple___Apple_scab  \n",
       "2  0.021123  Apple___Apple_scab  \n",
       "3  0.015042  Apple___Apple_scab  \n",
       "4  0.033135  Apple___Apple_scab  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data=pd.read_csv(r'C:\\Users\\pavan\\Downloads\\leaf_data_set.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=data.iloc[:,0:32]\n",
    "y=data.iloc[:,32]\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "x_train = sc.fit_transform(x_train)\n",
    "x_test = sc.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCURACY OF THE MODEL:  0.5697738554881412\n",
      "F1 SCORE OF THE MODEL:  0.4569030747834686\n",
      "RECALL OF THE MODEL:  0.45647726034180414\n",
      "PRECISION OF THE MODEL:  0.4781476104322852\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "tree= DecisionTreeClassifier(criterion=\"entropy\", max_depth=10)\n",
    "\n",
    "tree.fit(x_train, y_train)\n",
    "predicted = tree.predict(x_test)\n",
    "print(\"ACCURACY OF THE MODEL: \", metrics.accuracy_score(y_test, predicted))\n",
    "print(\"F1 SCORE OF THE MODEL: \", metrics.f1_score(y_test, predicted,average='macro'))\n",
    "print(\"RECALL OF THE MODEL: \", metrics.recall_score(y_test, predicted,average='macro'))\n",
    "print(\"PRECISION OF THE MODEL: \", metrics.precision_score(y_test, predicted,average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCURACY OF THE MODEL:  0.694980694980695\n",
      "F1 SCORE OF THE MODEL:  0.6104074935034023\n",
      "RECALL OF THE MODEL:  0.6007829795726386\n",
      "PRECISION OF THE MODEL:  0.64382042359245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "logmodel = LogisticRegression()\n",
    "logmodel.fit(x_train,y_train)\n",
    "predictions = logmodel.predict(x_test)\n",
    "print(\"ACCURACY OF THE MODEL: \", metrics.accuracy_score(y_test, predictions))\n",
    "print(\"F1 SCORE OF THE MODEL: \", metrics.f1_score(y_test, predictions,average='macro'))\n",
    "print(\"RECALL OF THE MODEL: \", metrics.recall_score(y_test, predictions,average='macro'))\n",
    "print(\"PRECISION OF THE MODEL: \", metrics.precision_score(y_test, predictions,average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCURACY OF THE MODEL:  0.7192498621070049\n",
      "F1 SCORE OF THE MODEL:  0.6179632002134836\n",
      "RECALL OF THE MODEL:  0.6007878220056981\n",
      "PRECISION OF THE MODEL:  0.7108349713858516\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_estimators = 1000)\n",
    "clf.fit(x_train, y_train)\n",
    "y_pred = clf.predict(x_test)\n",
    "from sklearn import metrics\n",
    "print(\"ACCURACY OF THE MODEL: \", metrics.accuracy_score(y_test, y_pred))\n",
    "print(\"F1 SCORE OF THE MODEL: \", metrics.f1_score(y_test, y_pred,average='macro'))\n",
    "print(\"RECALL OF THE MODEL: \", metrics.recall_score(y_test, y_pred,average='macro'))\n",
    "print(\"PRECISION OF THE MODEL: \", metrics.precision_score(y_test, y_pred,average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCURACY OF THE MODEL:  0.7079977937120794\n",
      "F1 SCORE OF THE MODEL:  0.6091935495693668\n",
      "RECALL OF THE MODEL:  0.6006450286384366\n",
      "PRECISION OF THE MODEL:  0.6320501220658374\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier  \n",
    "classifier= KNeighborsClassifier(n_neighbors=5, metric='minkowski', p=2 )  \n",
    "classifier.fit(x_train, y_train) \n",
    "y_pred= classifier.predict(x_test)  \n",
    "print(\"ACCURACY OF THE MODEL: \", metrics.accuracy_score(y_test, y_pred))\n",
    "print(\"F1 SCORE OF THE MODEL: \", metrics.f1_score(y_test, y_pred,average='macro'))\n",
    "print(\"RECALL OF THE MODEL: \", metrics.recall_score(y_test, y_pred,average='macro'))\n",
    "print(\"PRECISION OF THE MODEL: \", metrics.precision_score(y_test, y_pred,average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCURACY OF THE MODEL:  0.7457253171538886\n",
      "F1 SCORE OF THE MODEL:  0.6369564041577269\n",
      "RECALL OF THE MODEL:  0.6220976737483972\n",
      "PRECISION OF THE MODEL:  0.6967643754992434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "classifier = SVC(kernel='rbf', random_state = 1)\n",
    "classifier.fit(x_train,y_train)\n",
    "y_pred = classifier.predict(x_test)\n",
    "print(\"ACCURACY OF THE MODEL: \", metrics.accuracy_score(y_test, y_pred))\n",
    "print(\"F1 SCORE OF THE MODEL: \", metrics.f1_score(y_test, y_pred,average='macro'))\n",
    "print(\"RECALL OF THE MODEL: \", metrics.recall_score(y_test, y_pred,average='macro'))\n",
    "print(\"PRECISION OF THE MODEL: \", metrics.precision_score(y_test, y_pred,average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class_level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Apple___Apple_scab</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Apple___Apple_scab</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Apple___Apple_scab</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Apple___Apple_scab</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Apple___Apple_scab</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          class_level\n",
       "0  Apple___Apple_scab\n",
       "1  Apple___Apple_scab\n",
       "2  Apple___Apple_scab\n",
       "3  Apple___Apple_scab\n",
       "4  Apple___Apple_scab"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = data.select_dtypes(include=[object])\n",
    "y.class_level.unique()\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "y = y.apply(le.fit_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(x_train)\n",
    "\n",
    "x_train = scaler.transform(x_train)\n",
    "x_test = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(10, 10, 10), max_iter=1000)\n",
    "mlp.fit(x_train, y_train.values.ravel())\n",
    "predictions = mlp.predict(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCURACY OF THE MODEL:  0.7485109199205824\n",
      "F1 SCORE OF THE MODEL:  0.6357785294077583\n",
      "RECALL OF THE MODEL:  0.6275324950758766\n",
      "PRECISION OF THE MODEL:  0.6615499738471742\n"
     ]
    }
   ],
   "source": [
    "print(\"ACCURACY OF THE MODEL: \", metrics.accuracy_score(y_test, predictions))\n",
    "print(\"F1 SCORE OF THE MODEL: \", metrics.f1_score(y_test, predictions,average='macro'))\n",
    "print(\"RECALL OF THE MODEL: \", metrics.recall_score(y_test, predictions,average='macro'))\n",
    "print(\"PRECISION OF THE MODEL: \", metrics.precision_score(y_test, predictions,average='macro'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
